{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line√°rn√≠ klasifikace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√ökolem cviƒçen√≠ je naprogramovat line√°rn√≠ klasifik√°tor, kter√Ω bude rozpozn√°vat objekty z datasetu CIFAR-10. **Vyu≈æijeme k tomu knihovnu pytorch.**\n",
    "\n",
    "Kromƒõ zn√°m√Ωch knihoven numpy, matplotlib a torch budeme pot≈ôebovat n√°sleduj√≠c√≠:\n",
    "- torchvision ... roz≈°i≈ôuj√≠c√≠ pytorch bal√≠k pro pytorch obsahuj√≠c√≠ datasety, funkce pro zpracov√°n√≠ obr√°zk≈Ø a p≈ôedtr√©novan√© modely konvoluƒçn√≠ch s√≠t√≠\n",
    "- tqdm ... vykresluje bƒõhem v√Ωpoƒçt≈Ø progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zp≈Øsob naƒç√≠t√°n√≠ dat kompletnƒõ z√°vis√≠ na zp≈Øsobu, jak√Ωm byla ulo≈æena. Zde pou≈æijeme popul√°rn√≠ dataset CIFAR-10, kter√Ω ƒçasto slou≈æ√≠ jako z√°kladn√≠ benchmark pro porovn√°n√≠ p≈ô√≠nosu nov√Ωch algoritm≈Ø v≈Øƒçi st√°vaj√≠c√≠m. √ökolem je klasifikace obr√°zk≈Ø do jedn√© z 10 t≈ô√≠d.\n",
    "\n",
    "Bal√≠k torchvision podporuje nƒõkter√© znam√© datasety, mezi nƒõ≈æ pat≈ô√≠ i CIFAR-10. Nemus√≠me tedy data stahovat z internetu manu√°lnƒõ, torchvision za n√°s v≈°e obstar√° automaticky. Data ulo≈æ√≠me do adres√°≈ôe `./data`. V≈°imnƒõme si flagu `train=True`, kter√Ω ≈ô√≠k√°, ≈æe se m√° naƒç√≠st tr√©novac√≠ mno≈æina datasetu CIFAR-10 (soubory `data_batch_*`).\n",
    "\n",
    "Tenhle koment√°≈ô zmƒõn√≠m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V√Ωsledn√Ω objekt se chov√° jako `list`, by≈• nen√≠ jeho odvozeninou (subclass). Indexuje tedy prvky od nuly, m√° definovanou d√©lku skrze `__len__` a podporuje `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zavola `__len__`\n",
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zavola `__getitem__` s parametrem (indexem) 5\n",
    "trainset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak vid√≠me, 6. prvek datasetu je *dvojice* sest√°vaj√≠c√≠ z obr√°zku a jeho indexu t≈ô√≠dy (label, target). Obr√°zek je defaultnƒõ navr√°cen jako typ `Image` knihovny Pillow (Python Imaging Library, PIL). Pokud je v√Ωstupem bu≈àky objekt tohoto typu, jupyter notebook to rozpozn√° a zobraz√≠ ho jako obr√°zek. `Image` m√° toti≈æ definovanou metodu `__html__`, j√≠≈æ d√° notebook p≈ôednost p≈ôed obvykl√Ωm `__repr__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainset[5][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objekt CIFAR datasetu obsahuje i textov√Ω popis t≈ô√≠d ve formƒõ pole (`list`) n√°zv≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 6. prvku\n",
    "trainset.classes[trainset[5][1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V≈°echny obr√°zky CIFAR datasetu jsou ulo≈æeny v atributu `.train_data`, co≈æ je 4D `numpy.ndarray`. Prvn√≠ dimenze odpov√≠d√° jednotliv√Ωm obr√°zk≈Øm, dal≈°√≠ pak ≈ô√°dk≈Øm, sloupc≈Øm a kan√°l≈Øm (RGB), tedy $50000 \\times 32 \\times 32 \\times 3$. Hodnoty jsou ulo≈æeny jako datov√Ω typ `uint8`, tedy v rozsahu 0...255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainset.data), trainset.data.shape, trainset.data.dtype, trainset.data.min(), trainset.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobnƒõ v≈°echny labely jsou ulo≈æeny v `.targets`, co≈æ je `list` ƒç√≠sel (`int`) o d√©lce poƒçtu obr√°zk≈Ø."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trainset.targets), len(trainset.targets), type(trainset.targets[0]), min(trainset.targets), max(trainset.targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokud chceme obr√°zk≈Ø vykreslit v√≠ce najednou, vhodnƒõj≈°√≠ pou≈æ√≠t matplotlib (pyplot). Pro ka≈ædou t≈ô√≠du vykresl√≠me po sloupc√≠ch 10 p≈ô√≠klad≈Ø, abychom vidƒõli, jak data vlastnƒõ vypadaj√≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, cls in enumerate(trainset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(trainset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(trainset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testovac√≠/validaƒçn√≠ data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testovac√≠ data ze souboru `test_batch` naƒçteme stejnƒõ jako tr√©novac√≠, pouze tentokr√°t nastav√≠me flag `train` na hodnotu `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(testset.classes):\n",
    "    # chceme pouze obrazky aktualni tridy a z nich nahodne vybereme 10\n",
    "    cls_ids = [j for j, y in enumerate(testset.targets) if y == i]\n",
    "    draw_ids = np.random.choice(cls_ids, size=10)\n",
    "    \n",
    "    # pyplot podobne jako MATLAB nabizi funkci subplot pro vykresleni vice grafu do jednoho okna\n",
    "    for j, k in enumerate(draw_ids):\n",
    "        # vykresli 10x10 obrazku, poradi je po radcich, ovsem my budeme vykreslovat po sloupcich,\n",
    "        # tj. kazdy sloupec bude obsahovat 10 prikladu jedne ze trid\n",
    "        plt.subplot(10, 10, j * 10 + i + 1)\n",
    "        \n",
    "        # vyresli obrazek\n",
    "        plt.imshow(testset.data[k])\n",
    "        \n",
    "        # nevykresluj popisky os\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # v prvnim radku pridame nazev grafu (obrazku)\n",
    "        if j == 0:\n",
    "            plt.title(cls, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matice tr√©novac√≠ch a validaƒçn√≠ch dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeliko≈æ pou≈æijeme jednoduch√Ω line√°rn√≠ klasifik√°tor, data **p≈ôevedeme do maticov√© formy**, ve kter√© ka≈æd√Ω ≈ô√°dek reprezentuje jeden obr√°zek. Pro lep≈°√≠ numerick√© chov√°n√≠ data nav√≠c z rozsahu `0...255` a typu `uint8` p≈ôevedeme do rozsahu `0...1` a datov√©ho typu s plovouc√≠ ≈ô√°dovou ƒç√°rkou.\n",
    "\n",
    "### Validaƒçn√≠ vs testovac√≠ mno≈æiny\n",
    "\n",
    "Testovac√≠ sada, kter√° je v p≈ô√≠padƒõ CIFAR-10 obsa≈æena v souboru `cifar-10-batches-py/test_batch`, by spr√°vnƒõ nemƒõla b√Ωt pou≈æ√≠v√°na pro validaci, tj. volbu modelu a ladƒõn√≠ hyperparametr≈Ø, ale pouze pro odhad √∫spƒõ≈°nosti natr√©novan√©ho klasifik√°toru na nevidƒõn√Ωch datech. Pokud pou≈æijeme testovac√≠ data pro validaci, efektivnƒõ t√≠m vyu≈æ√≠v√°me informaci v nich obsa≈æenou pro uƒçen√≠ modelu. Takto dosa≈æen√° sk√≥re bychom proto nemƒõli uv√°dƒõt jako odhad √∫spƒõ≈°nosti na nevidƒõn√Ωch datech, m≈Ø≈æe b√Ωt toti≈æ p≈ô√≠li≈° optimistick√Ω."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevedeme na pytorch tensor\n",
    "X_train = torch.tensor(trainset.data)\n",
    "\n",
    "# na vychozi datovy typ (float nebo double, lze menit) a do rozsahu 0...1\n",
    "X_train = X_train.to(torch.get_default_dtype()) / 255.\n",
    "\n",
    "# reshape na matici s obrazky na radcich\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "X_train.dtype, X_train.shape, X_train.min(), X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labely** tr√©novac√≠ch dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.tensor(trainset.targets)\n",
    "y_train.dtype, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matice **validaƒçn√≠ch** dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevedeme na pytorch tensor\n",
    "X_valid = torch.tensor(testset.data)\n",
    "\n",
    "# na vychozi datovy typ (float nebo double, lze menit) a do rozsahu 0...1\n",
    "X_valid = X_valid.to(torch.get_default_dtype()) / 255.\n",
    "\n",
    "# reshape na matici s obrazky na radcich\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
    "\n",
    "X_valid.dtype, X_valid.shape, X_valid.min(), X_valid.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labely** validaƒçn√≠ch dat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = torch.tensor(testset.targets)\n",
    "y_valid.dtype, y_valid.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax (logistick√° regrese)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P≈ôipome≈àme, ≈æe logistick√° regrese je jednoduch√Ω line√°rn√≠ klasifik√°tor s parametry:\n",
    "\n",
    "- v√°hov√° matice $W$\n",
    "  - rozmƒõr `rozmƒõr_vstupu x poƒçet_t≈ô√≠d`\n",
    "  - inicializujeme na mal√© n√°hodn√© hodnoty\n",
    "  - v k√≥du oznaƒç√≠me jako `W_smax` (v√°hy softmaxu)\n",
    "- bias vektor $b$\n",
    "  - rozmƒõr `poƒçet_t≈ô√≠d`\n",
    "  - inicializujeme na vektor nul\n",
    "  - v k√≥du oznaƒç√≠me jako `b_smax` (bias softmaxu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "W_smax = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "W_smax.dtype, W_smax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "b_smax = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "b_smax.dtype, b_smax.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tr√©nov√°n√≠ metodou online SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dop≈ôedn√Ω pr≈Øchod\n",
    "1. Pokud m√°me na vstupu *jeden* obr√°zek $x$, vektor line√°rn√≠ho sk√≥re pro jednotliv√© t≈ô√≠dy je\n",
    "$$ s \\leftarrow W x + b $$\n",
    "a tedy $s \\in \\mathbb{R}^C$, kde $C$ znaƒç√≠ celkov√Ω poƒçet t≈ô√≠d.\n",
    "\n",
    "2. Vektor sk√≥re $s$ d√°le proch√°z√≠ softmaxem. Z√≠sk√°me vektor $p$, ve kter√©m $i$-t√Ω prvek znaƒç√≠ pravdƒõpodobnost, ≈æe $x$ pat≈ô√≠ do t≈ô√≠dy $i$.\n",
    "$$ p \\leftarrow \\frac{\\exp{s}}{\\sum_{c=0}^{C-1}\\exp{s_c}} $$\n",
    "V√Ωsledn√© $p$ m√° tedy stejn√Ω rozmƒõr jako $s$ a plat√≠ $\\sum_{c}p_c=1$.\n",
    "\n",
    "3. Zda a jak moc byla predikce spr√°vn√° urƒç√≠ kriteri√°ln√≠ funkce (loss), tzv. cross entropy, kter√° ve speci√°ln√≠m p≈ô√≠padƒõ klasifikace do jedn√© z $C$ t≈ô√≠d m√° tvar\n",
    "$$L \\leftarrow -\\log p_y$$\n",
    "kde $y\\in\\{1,\\ldots,C\\}$ je index t≈ô√≠dy, do kter√© obr√°zek ve skuteƒçnosti pat≈ô√≠ (label/target obr√°zku).\n",
    "\n",
    "##### Regularizace\n",
    "\n",
    "Regularizace penalizuje p≈ô√≠li≈° velk√© hodnoty vah $W$. Nejƒçastƒõji se setk√°me s typem L2, u nƒõj≈æ k v√Ωsledn√© hodnotƒõ lossu p≈ôiƒç√≠t√°me dodateƒçn√Ω ƒçlen\n",
    "$$\\lambda\\sum_{ij}w_{ij}^2$$\n",
    "kde $w_{ij}$ je v√°ha na $i$-t√©m ≈ô√°dku a $j$-t√©m sloupci matice $W$ a $\\lambda$ je hyperparametr vyjad≈ôuj√≠c√≠ v√°hu regularizace (v k√≥du je $\\lambda$ oznaƒçen√° jako promƒõnn√° `l2_decay`).\n",
    "\n",
    "Pro lep≈°√≠ monitoring hodnoty lossu **regularizaci nep≈ôiƒç√≠tejte**, ale dr≈æte ji zvl√°≈°≈• v promƒõnn√© `l2_val`.\n",
    "\n",
    "#### Zpƒõtn√Ω pr≈Øchod\n",
    "1. Vzorec pro gradient na $c$-t√Ω ≈ô√°dek v√°hov√© *matice* je (≈ô√°dek pro spr√°vnou t≈ô√≠du se od ostatn√≠ch li≈°√≠)\n",
    "$$ \\frac{\\partial L}{\\partial w_c} \\leftarrow \\left(p_c - \\boldsymbol{1}(c=y)\\right) x^\\top $$\n",
    "\n",
    "2. Gradient na $c$-t√Ω prvek bias *vektoru* (prvek pro spr√°vnou t≈ô√≠du se od ostatn√≠ch li≈°√≠)\n",
    "$$ \\frac{\\partial L}{\\partial b_c} \\leftarrow p_c - \\boldsymbol{1}(c=y) $$\n",
    "\n",
    "##### Regularizace\n",
    "\n",
    "Pokud pou≈æ√≠v√°me regularizaci vah $W$, je≈°tƒõ p≈ôed updatem parametr≈Ø $W$ a $b$ uprav√≠me ${\\partial L} / {\\partial W}$ gradientem regularizaƒçn√≠ho ƒçlenu (ten zvl√°dnete sami). Nezapome≈àte na v√°hu regularizace $\\lambda$.\n",
    "\n",
    "#### Gradient descent update \n",
    "\n",
    "1. Update vah $W$\n",
    "$$ W \\leftarrow W - \\gamma \\frac{\\partial L}{\\partial W} $$\n",
    "kde $\\gamma$ je velikost kroku gradient descentu (learning rate)\n",
    "\n",
    "2. Update biasu $b$\n",
    "$$ b \\leftarrow b - \\gamma \\frac{\\partial L}{\\partial b} $$\n",
    "\n",
    "### Pozn√°mky\n",
    "\n",
    "- Popsan√Ω zp≈Øsob a kostra k√≥du odpov√≠d√° tr√©nov√°n√≠ online variantou gradient descentu (stochastic gradient descent, SGD), tzn. update parametr≈Ø n√°sleduje po ka≈æd√©m vstupn√≠m vektoru, nikoliv po zpracov√°n√≠ v≈°ech dat.\n",
    "- Ve vzoreƒçc√≠ch se pracuje s vektorem $x$ jako se sloupcem, ale data v `X_train` jsou po ≈ô√°dc√≠ch a matice vah $W$ m√° rozmƒõr `rozmƒõr_vstupu x poƒçet_t≈ô√≠d`. V k√≥du proto budou v√Ωpoƒçty transponovan√©, tj. $s = x W + b$ a vzorec pro gradient na $c$-t√Ω *≈ô√°dek* matice $W$ bude ve skuteƒçnosti vzorec na $c$-t√Ω sloupec!\n",
    "  \n",
    "  \"Proboha proƒç?\", pt√°te se? Teorie vych√°z√≠ ze zaveden√© konvence v line√°rn√≠ algeb≈ôe, kde jsou vektory uva≈æov√°ny jako sloupcov√© a strojov√© uƒçen√≠ t√≠mto zp≈Øsobem popisuje i vƒõt≈°ina dopstupn√© literatury. Pro zachov√°n√≠ \"kompatibility\" materi√°l≈Ø tak postpujejme i zde. Tuto konvenci kdysi d√°vno p≈ôevzal jazyk Fortran a v n√°vaznosti na nƒõj i MATLAB, a proto maj√≠ tyto jazyky matice ulo≈æen√© po sloupc√≠ch. V jazyc√≠ch jako Python (pota≈æmo v knihovn√°ch numpy a pytorch) jsou v≈°ak matice tzv. row-major, a tedy daty ulo≈æen√Ωmi typicky po ≈ô√°dc√≠ch, a bez transpozice rovnic by se musela transponovat data $x$, co≈æ by bylo v√Ωpoƒçetnƒõ neefektivn√≠.\n",
    "  \n",
    "- Vƒõt≈°ina operac√≠ (nap≈ô. funkce `argmax`) v pytorchi vrac√≠ `torch.tensor`, i kdy≈æ je v√Ωsledkem jedin√© re√°ln√© ƒç√≠slo. V takov√©m p≈ô√≠padƒõ lze obvykle p≈ôev√©st na pythonovsk√Ω built-in typ jednodu≈°e jako nap≈ô. `int(pytorch_tensor)`.\n",
    "\n",
    "- Odlaƒète tr√©novac√≠ cyklus nejprve pro `num_iters = 1`, pak teprve spus≈•te na velk√Ω poƒçet iterac√≠ (nap≈ô. roven poƒçtu tr√©novac√≠ch obr√°zk≈Ø = 1 epocha). Poka≈æd√©, kdy≈æ nƒõco sel≈æe, sledujte hodnoty a tvar matic (vektor≈Ø) sk√≥re, vah apod. v jednotliv√Ωch kroc√≠ch tak, ≈æe si vytvo≈ô√≠te novou bu≈àku a prozkoum√°te, co se s nimi dƒõje.\n",
    "\n",
    "- Hyperparametry $\\gamma$ (`learning_rate`) a $\\lambda$ (`l2_decay`) nastavte na mal√© hodnoty $\\ll 1$ a optimalizujte tak, abyste dos√°hli co nejlep≈°√≠ho sk√≥re na validaƒçn√≠ch datech. Krok gradient descentu `learning_rate` m≈Ø≈æete p≈ôi opakovan√Ωch pr≈Øchodech daty (epochy) postupnƒõ sni≈æovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparametry\n",
    "learning_rate = \n",
    "l2_decay = \n",
    "num_iters = \n",
    "\n",
    "# akumulator\n",
    "num_correct = 0\n",
    "loss = 0.\n",
    "l2_val = 0.\n",
    "\n",
    "# hlavni trenovaci cyklus\n",
    "pb = tqdm.tnrange(num_iters)\n",
    "for n in pb:\n",
    "    # obrazek vybereme nahodne\n",
    "    idx = int(torch.randint(X_train.shape[0], (1,)))\n",
    "    \n",
    "    # ziskame data\n",
    "    xn = X_train[idx]\n",
    "    yn = y_train[idx]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    prob = \n",
    "    loss += \n",
    "    l2_val += \n",
    "    \n",
    "    # gradient na skore (clen $(ùëùùëê‚àí1(ùëê=ùë¶))$ ve vzorecku dL/dw_c)\n",
    "    dscore = \n",
    "    \n",
    "    # gradient na vahy\n",
    "    dW = \n",
    "    \n",
    "    # gradient na bias\n",
    "    db = \n",
    "    \n",
    "    # regularizace (volitelna; modifikuje gradient na vahy)\n",
    "    dW += \n",
    "    \n",
    "    # update parametru\n",
    "    W_smax \n",
    "    b_smax\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "    \n",
    "    # prubezny vypis\n",
    "    if n % 100 == 0:\n",
    "        pb.set_postfix(loss='{:.3f}'.format(float(loss / (n + 1))), acc='{:.3f}'.format(num_correct / (n + 1)))\n",
    "\n",
    "print('train accuracy: {}/{} = {:.1f} %'.format(num_correct, n, 100. * num_correct / n))\n",
    "print(float(loss) / n, float(l2_val) / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace\n",
    "\n",
    "\n",
    "Natr√©novan√Ω klasifik√°tor ovƒõ≈ô√≠me na validaƒçn√≠ (development) mno≈æinƒõ. Ide√°lnƒõ bychom mƒõli dos√°hnout stejn√© √∫spƒõ≈°nosti jako na tr√©novac√≠ sadƒõ, pravdƒõpodobnƒõ tomu tak ale nebude. Proƒç?\n",
    "\n",
    "**Postup je jednodu≈°≈°√≠ ne≈æ v p≈ô√≠padƒõ tr√©nov√°n√≠:**\n",
    "1. Dop≈ôedn√Ω pr≈Øchod\n",
    "$$ s \\leftarrow W x + b $$\n",
    "\n",
    "2. Nen√≠ t≈ôeba poƒç√≠tat pravdƒõpodobnosti. Softmax pouze znormalizuje sk√≥re tak, aby v√Ωsledn√° ƒç√≠sla tvo≈ôila rozdƒõlen√≠ pravdƒõpodobnosti. Pokud je ve vektoru $s$ max. hodnota na pozici $i$, pak bude $i$-t√Ω prvek max. i ve vektoru $p$. Staƒç√≠ tedy porovnat index $i$ s labelem obr√°zku $y$ a pokud se rovnaj√≠, je predikce spr√°vn√°, jinak ne. V√Ωsledn√© sk√≥re pak bude pod√≠l spr√°vnƒõ klasifikovan√Ωch obr√°zk≈Ø v≈Øƒçi celkov√©mu poƒçtu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in tqdm.tnrange(X_valid.shape[0]):   \n",
    "    # ziskame data\n",
    "    xn = X_valid[n]\n",
    "    yn = y_valid[n]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "\n",
    "print('val accuracy: {}/{} = {:.1f} %'.format(num_correct, n, 100. * num_correct / n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weston-Watkins SVM\n",
    "\n",
    "Jak jsme si uk√°zali v p≈ôedn√°≈°ce, SVM je softmaxu velmi podobn√©. Z pohledu neuronov√Ωch s√≠t√≠ se li≈°√≠ pouze zp≈Øsobem v√Ωpoƒçtu lossu - m√≠sto cross entropy pou≈æijeme hinge loss definovan√Ω jako\n",
    "$$L = \\sum_{c\\ne y}\\max(0, 1 + s_c - s_y)$$\n",
    "kde $s$ je vektor line√°rn√≠ch sk√≥re $s=Wx + b$.\n",
    "\n",
    "Gradient na v√°hy pak je\n",
    "$$\\frac{\\partial L}{\\partial w_y} = -\\sum_{c\\ne y}\\boldsymbol{1}(1 + s_c - s_y > 0)x$$\n",
    "$$\\frac{\\partial L}{\\partial w_{c\\ne y}} = \\boldsymbol{1}(1 + s_c - s_y > 0)x$$\n",
    "a pro biasy podobnƒõ, pouze bez n√°soben√≠ $x$ (na konci)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "W_svm = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "W_svm.dtype, W_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# ZDE DOPLNIT\n",
    "\n",
    "b_svm = \n",
    "\n",
    "#################################################################\n",
    "\n",
    "b_svm.dtype, b_svm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tr√©nov√°n√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# hyperparametry\n",
    "learning_rate = \n",
    "l2_decay = \n",
    "num_iters = \n",
    "\n",
    "# akumulator\n",
    "num_correct = 0\n",
    "loss = 0.\n",
    "l2_val = 0.\n",
    "\n",
    "# hlavni trenovaci cyklus\n",
    "pb = tqdm.tnrange(num_iters)\n",
    "for n in pb:\n",
    "    # obrazek vybereme nahodne\n",
    "    idx = int(torch.randint(X_train.shape[0], (1,)))\n",
    "    \n",
    "    # ziskame data\n",
    "    xn = X_train[idx]\n",
    "    yn = y_train[idx]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    margin = \n",
    "    loss += \n",
    "    l2_val += \n",
    "    \n",
    "    # gradient na bias\n",
    "    db = \n",
    "    \n",
    "    # gradient na vahy\n",
    "    dW = \n",
    "    \n",
    "    # regularizace (modifikuje gradient na vahy)\n",
    "    dW += \n",
    "    \n",
    "    # update parametru\n",
    "    W_svm\n",
    "    b_svm\n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "    \n",
    "    # prubezny vypis\n",
    "    if n % 100 == 0:\n",
    "        pb.set_postfix(loss='{:.3f}'.format(float(loss / (n + 1))), acc='{:.3f}'.format(num_correct / (n + 1)))\n",
    "\n",
    "print('train accuracy: {}/{} = {:.1f} %'.format(num_correct, num_iters, 100. * num_correct / num_iters))\n",
    "print(float(loss) / num_iters, float(l2_val) / num_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_correct = 0\n",
    "\n",
    "for n in tqdm.tnrange(X_valid.shape[0]):   \n",
    "    # ziskame data\n",
    "    xn = X_valid[n]\n",
    "    yn = y_valid[n]\n",
    "    \n",
    "    #################################################################\n",
    "    # ZDE DOPLNIT\n",
    "    \n",
    "    # dopredny pruchod: linearni skore, sigmoida a loss\n",
    "    score = \n",
    "    \n",
    "    #################################################################\n",
    "    \n",
    "    if score.argmax() == yn:\n",
    "        num_correct += 1\n",
    "\n",
    "print('val accuracy: {}/{} = {:.1f} %'.format(num_correct, X_valid.shape[0], 100. * num_correct / X_valid.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
